[![Generic badge](https://img.shields.io/badge/ENSAE-ML%20for%20NLP-blue.svg)](https://shields.io/)
[![made-with-python](https://img.shields.io/badge/Made%20with-Python-red.svg)](#python) [![Open In Collab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/Naereen/badges)


The report linked to this repository is available here : 

# Overview
In this work\footnote{https://github.com/NLP-ENSAE-3A/French-Political-Tweets-Generation}, we attempted to create a sequence-generation model that aims to replicate phraseologic patterns from an homegenous
political group. Our main motivation is to investigate the ability of our model to simulate thematic discourse and subtle languages nuances that could pass as genuine. Thereby, we our project is structured around the following question : is it possible to create bots that could actually perform \emph{astroturfing} and interfere in the political/social debate with relatively modest data and modelling techniques ?

# Discussion

We were able to generate an interesting but rather
modest proportion of astonishingly accurate
tweets in terms of the replication of the political
discourse we targeted (see appendix). The GPT2
model ability to capture themes as well as syntax
and writing style opens the door for astroturfing
even with small resources and limited data.
A direct improvement path would consist in
scaling the complexity of the model and the size
of the dataset i.e bigger GPT2 model fine-tuned
on TBs of french data and millions of relevant
tweets. Having the ability to generate a significant
proportion of precisely replicated tweets will rise
serious ethical concerns as it directly opens the
door for mass manipulation on social media. This
work really allowed us to understand the power of
NLP tools and the sheer necessity to poise it with
responsibility and an increased consciousness
when we deal with online content.
